消息中间件--Kafka 详解
====================

## 1 Kafka 概述

### 1.1 Kafka 简介

> Kafka 官网：是一个分布式发布-订阅消息传递系统。

Kafka 最初由 LinkedIn 公司开发，LinkedIn 于 2010 年贡献给了 Apache 基金会并成为顶级开源项目。Kafka 是一种快速、可扩展的，支持分区的（partition）、多副本的（replica），基于 ZK 协调的分布式流处理平台。

### 1.2 Kafka 特性

- **高吞吐量、低延迟**：Kafka 每秒可以处理几十万条消息，它的延迟最低只有几毫秒；
- **可扩展性**：Kafka 集群支持热扩展；
- **持久性、可靠性**：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失；
- **容错性**：允许集群中节点失败（若副本数量为n，则允许n-1个节点失败）；
- **高并发**：支持数千个客户端同时读写。

### 1.3 Kafka 应用场景

- **日志收集**：使用 Kafka 收集各种服务的 log，通过 Kafka 以统一接口服务的方式开放给各 consumer 进行消费，如 Hadoop、Hbase、Solr 等。

- **消息系统**：解耦和生产者和消费者、缓存消息等。

- **用户活动跟踪**：使用 Kafka 记录 web 用户或者 app 用户的各种活动，如：浏览网页、搜索、点击等，这些活动信息被各个服务器发布到 Kafka 的 topic 中，然后消费者通过订阅这些 Topic 来做实时的监控分析，或者装载到 Hadoop、在数据仓库中做离线分析和挖掘。

- **运营指标**：使用 Kafka 记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作（如：报警、报告）的集中反馈。

- **流式处理**：如大数据的 spark streaming 和 storm。

## 2 Kafka 的架构和原理

### 2.1 Kafka 的架构图

Kafka 的架构图如下：

<img src=".\images\2201.png" style="zoom: 67%;" />

各名词解释如下：

- **消息生产者（Producer）**：向 broker **push 消息**的客户端。
- **消息消费者（Consumer）**：从 broker **pull 消息**的客户端。

- **代理（Broker）**：一台 kafka 服务器就是一个 broker，一个集群由多个 broker 组成，一个 broker 可以容纳多个 topic。
- **消息主题（Topic）**：可以理解为一个队列，一个 Topic 又分为一个或多个分区。Topic 可用于**消息分类**，即不同类型的消息可存放在不同的 Topic。
- **主题分区（Partition）**：为了实现扩展性，一个非常大的 Topic 可以分布到多个 Broker 上，一个 Topic 可以分为多个 Partition，每个 Partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。kafka 只保证按一个 partition 中的顺序将消息发给 consumer，不保证一个 topic 的整体（多个 partition 间）的顺序。
- **偏移量（Offset）**：消费者消费的位置信息，监控数据消费到什么位置，当消费者挂掉再重新恢复的时候，可以从消费位置继续消费。
- **副本（Replica）**：为实现备份的功能，保证集群中的某个节点发生故障时，该节点上的 Partition 数据不丢失，且 Kafka 仍然能够继续工作，Kafka 提供了副本机制，一个 Topic 的每个分区都有若干个副本，一个 Leader 和若干个 Follower。
- **消费者组（Consumer Group）**：我们可以将多个消费组成一个消费者组，在 kafka 的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量
- **Leader**：每个分区多个副本的“主”副本，生产者发送数据以及消费者消费数据的对象都是 Leader。
- **Follower**：每个分区多个副本的“从”副本，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。

### 2.2 Zookeeper 协调控制

Kafka 集群能够正常工作，需要依赖于 zk，zk 帮助 Kafka 存储和管理集群信息。

- **Broker 注册**：Broker 是分布式部署并且之间相互独立，zk 用来管理注册到集群的所有 Broker 节点；
- **Topic 注册**： 在 Kafka 中，同一个 Topic 的消息会被分成多个 Partition 并将其分布在多个 Broker 上，这些分区信息及与 Broker 的对应关系也都是由 zk 维护；
- **生产者负载均衡**：由于同一个 Topic 消息会被分区并将其分布在多个 Broker 上，因此，生产者需要将消息合理地发送到这些分布式的 Broker 上；
- **消费者负载均衡**：与生产者类似，Kafka 中的消费者同样需要进行负载均衡来实现多个消费者合理地从对应的 Broker 服务器上接收消息，每个消费者分组包含若干消费者，每条消息都只会发送给分组中的一个消费者，不同的消费者分组消费自己特定的 Topic 下面的消息，互不干扰。

### 2.3 Kafka 的基本原理

根据架构图和 zk 协调控制，归纳 Kafka 的基本原理：

- 生产者 push 数据给 broker 进行存储，消费者从 broker 中 pull 数据，并完成一系列数据处理操作。
- 多个 broker 间的协同合作，producer 和 consumer 部署在各个业务逻辑中被频繁的调用，三者通过 zk 管理协调请求和转发，从而实现了一个高性能的分布式消息发布订阅系统。

## 3 Kafka 的工作流程

介绍完 "Kafka 的架构和原理" 后，从消息（数据）的生命周期角度介绍 Kafka 的工作流程。

### 3.1 发送数据

生产者发送消息流程如下图：

<img src=".\images\2202.png" style="zoom: 67%;" />

生产者发送消息流程说明如图中文字描述，下面就流程中的要点进行说明：

- 消息写入 leader 后，follower 是主动的去 leader 进行数据同步的（pull 消息）；

- producer 采用 push 模式将数据发布到 broker，每条消息追加到分区中，顺序写入磁盘，所以保证了**同一分区**内的数据是有序的。写入示意图如下：

  <img src=".\images\2203.png" style="zoom: 50%;" />

- **kafka 分区的目的**：
  
  - **方便扩展**。因为一个 topic 可以有多个 partition，所以可以通过扩展机器去轻松的应对日益增长的数据量；
  - **提高并发**。以 partition 为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。
  
- kafka 中，如果某个 topic 有多个 partition，producer 又怎么知道该将数据发往哪个 partition 呢？**kafka 的分区原则**：
  - 在写入 partition 的时，可以指定需要写入的 partition，若有指定，则写入对应的 partition；
  - 若没有指定 partition，但是设置了数据的 key，则会根据 key的值 hash 出一个 partition；
  - 如果既没指定 partition，又没有设置 key，第一次调用时随机生成一个整数(后面调用在这个整数上自增)，将这个值与可用的分区数取余，得到 partition 值，也就是常说的 **Round-Robin 轮询算法**。
- producer 向 kafka 写入消息时，通过**ACK应答机制，保证消息不丢失**。在生产者向队列写入数据时，可以设置参数来确定是否确认 kafka 接收到数据，这个参数可设置的值为**0**、**1**、**all**。
  - **0** 代表 producer 往集群发送数据不需要等到集群的返回，不确保消息发送成功；安全性最低、效率最高。
  - **1** 代表 producer 往集群发送数据只要 leader 应答就可以发送下一条，只确保 leader 发送成功。
  - **all** 代表 producer 往集群发送数据需要所有的 follower 都完成从 leader 的同步才会发送下一条，确保leader 发送成功和所有的副本都完成备份。安全性最高、效率最低。

- 如果往不存在的 topic 写数据，kafka 会自动创建 topic，分区和副本的数量根据默认配置都是 1。

### 3.2 保存数据

kafka 将数据保存在磁盘，而在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka 初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。

#### 3.2.1 Partition 结构

前面说过了每个 topic 都可以分为一个或多个 partition。partition 在服务器上的表现形式就是一个一个的文件夹，每个 partition 文件夹下面会有多组 segment 文件，每组 segment 文件又包含 .index 文件、.log 文件、.timeindex 文件（早期版本中没有）三个文件； log 文件就实际是存储 message 的地方，而 index 和timeindex 文件为索引文件，用于检索消息。Partition 结构如下图：

<img src=".\images\2204.png" style="zoom: 67%;" />

如上图，这个 partition 有三组 segment 文件，每个 log 文件的大小是一样的，但是存储的 message 数量是不一定相等的（每条 message 的大小不一致）。文件的命名是以该 segment 最小 offset 来命名的，如：000.index 存储 offset 为 0~368795 的消息，**kafka 就是利用分段+索引的方式来解决查找效率的问题**。

#### 3.2.2 Message 结构

上面说到 log 文件就实际是存储 message 的地方，我们在 producer 往 kafka 写入的也是一条一条的 message。

消息主要包含**消息体、消息大小、offset、压缩类型**等！我们重点需要知道的是下面三个：

- **offset**：是一个占 8byte 的有序 id 号，它可以唯一确定每条消息在 parition 内的位置；
- **消息大小**：消息大小占用 4byte，用于描述消息的大小。
- **消息体**：消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。

#### 3.2.3 存储策略

无论消息是否被消费，kafka 都会保存所有的消息。那对于旧数据有什么删除策略呢？

- **基于时间**，默认配置是168小时（7天）。

- **基于大小**，默认配置是1073741824。

需要注意的是，kafka 读取特定消息的时间复杂度是O(1)，所以这里删除过期的文件并不会提高 kafka 的性能！

### 3.3 消费数据

消息存储 log 文件后，消费者就可以从 leader 拉取消息进行消费了。

多个消费者可以组成一个**消费者组（consumer group）**，每个消费者组都有一个组 id；同一个消费组者的消费者可以消费同一 topic 下不同分区的数据，但是不会组内多个消费者消费同一分区的数据。我们看下图：

<img src=".\images\2205.png" style="zoom: 67%;" />

图示是消费者组内的消费者小于 partition 数量的情况，所以会出现某个消费者消费多个 partition 数据的情况，于是消费的速度也就不及只处理一个 partition 的消费者的处理速度。所以在实际的应用中，建议**消费者组的consumer 的数量与 partition 的数量一致。**

在 “3.2 保存数据” 里面，我们聊到了 partition 划分为多组 segment，每个 segment 包含了 .log、.index、.timeindex 文件，存放的每条 message 包含 offset、消息大小、消息体等。

我们多次提到 segment 和 offset，那么查找消息的时候是怎么利用 segment+offset 进行配合查找的呢？我们通过如下例子进行说明。

> 假如现在需要查找一个 offset 为 368801 的 message 是什么样的过程呢？

<img src=".\images\2206.png" style="zoom: 67%;" />

分析如上图，查找过程说明如下：

- 先找到 offset 的 368801 message 所在的 segment 文件（利用二分法查找），找到第二个 segment 文件。
- 打开找到 segment 中的 .index 文件（368796.index 文件，该文件起始偏移量为 368796+1，我们要查找的offset 为 368801 的message 在该 index 内的偏移量为 368796+5=368801，所以**相对offset**为5）。由于该文件采用的是**稀疏索引**的方式存储着相对 offset 及对应 message 物理偏移量的关系，所以直接找相对 offset为5的索引是找不到的。需使用二分法查找相对 offset 小于或者等于指定的相对 offset 的索引条目中最大的那个相对 offset，所以找到的是相对 offset 为 4 的这个索引。
- 根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。

这套机制是建立在 offset 为有序的基础上，利用 **segment**+**有序offset**+**稀疏索引**+**二分查找**+**顺序查找**等多种手段来高效的查找数据。


# 参考

- [Kafka 中文文档 - ApacheCN](https://kafka.apachecn.org/)
- [32 道常见的 Kafka 面试题](https://www.iteblog.com/archives/2605.html)
- [再过半小时，你就能明白kafka的工作原理了](https://www.cnblogs.com/sujing/p/10960832.html)
- [Kafka架构原理，也就这么回事！](https://developer.51cto.com/art/202003/611798.htm)
- https://www.zhihu.com/question/56172498
