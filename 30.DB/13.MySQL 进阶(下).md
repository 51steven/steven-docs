MySQL 进阶（下）
====================
# 1 MySQL 事务
MySQL 事务主要用于处理操作量大，复杂度高的数据。实际业务中，对数据信息的增、删、改等操作语句都将构成一个事务。

## 1.1 事务的 4 要素
事务是由一组 SQL 语句组成的逻辑处理单元，具有 4 个属性：原子性（Atomicity，简称 A）、一致性（Consistency，C）、隔离性（Isolation，I）、持久性（Durability，D），简称为事务的 ACID 属性。

- 原子性（A）：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样；

- 一致性（C）：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏；

- 隔离性（I）：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。

- 持久性（D）：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。

## 1.2 并发事务处理带来的问题
- 更新丢失（Lost Update)：事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题。

- 脏读(Dirty Reads)：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。
  
- 不可重复读（Non-Repeatable Reads)：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

- 幻读（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

### 幻读和不可重复读的区别：
- **不可重复读的重点是修改**。在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）
- **幻读的重点在于新增或者删除**。在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

### 并发事务处理带来的问题的解决办法：
- “更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。

- “脏读” 、“不可重复读”和“幻读” ，都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决：
  - 加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。
  - 数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC）：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot)， 并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。

## 1.3 事务隔离级别
数据库事务的隔离级别有4种，由低到高分别为:
- READ-UNCOMMITTED(读未提交)：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

- READ-COMMITTED(读已提交)：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。

- REPEATABLE-READ(可重复读)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。（InnoDB 存储引擎的默认支持的隔离级别）

- SERIALIZABLE(可串行化)：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

查看当前数据库的事务隔离级别：``show variables like 'tx_isolation';``

数据库的事务隔离越严格，并发副作用越小，但付出的代价就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读已提交):，但是 InnoDB 存储引擎默认使用 REPEATABLE-READ（可重读）并不会有任何性能损失。

## 1.4 数据多版本并发控制（MVCC）
MySQL 的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL，只是实现机制各不相同。

MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。

典型的 MVCC 实现方式，分为乐观并发控制和悲观并发控制。下边通过 InnoDB 的简化版行为来说明 MVCC 是如何工作的。

InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。其中，一列保存了行的创建时间，另一列保存行的过期时间（删除时间。当然存储的并不是真实的时间，而是系统版本号，每开始一个新的事务，系统版本号都会自动递增；事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

### REPEATABLE READ（可重读）隔离级别下 MVCC 如何工作：
- SELECT 语句，InnoDB 会根据以下两个条件检查每行记录，只有符合上述两个条件的才会被查询出来；
  - InnoDB 只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的；
  - 行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除；

- INSERT 语句，InnoDB 为新插入的每一行保存当前系统版本号作为行版本号；

- DELETE 语句，InnoDB 为删除的每一行保存当前系统版本号作为行删除标识；

- UPDATE 语句，InnoDB 为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识。

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。

## 1.5 事务日志
InnoDB 使用日志来减少提交事务时的开销。因为日志中已经记录了事务，就无须在每个事务提交时把缓冲池的脏块刷新(flush)到磁盘中。

事务修改的数据和索引通常会映射到表空间的随机位置，所以刷新这些变更到磁盘需要很多随机 IO。InnoDB 假设使用常规磁盘，随机 IO 比顺序 IO 昂贵得多，因为一个 IO 请求需要时间把磁头移到正确的位置，然后等待磁盘上读出需要的部分，再转到开始位置。

InnoDB 用日志把随机 IO 变成顺序 IO。一旦日志安全写到磁盘，事务就持久化了，即使断电了，InnoDB 可以重放日志并且恢复已经提交的事务。InnoDB 使用一个后台线程智能地刷新这些变更到数据文件。这个线程可以批量组合写入，使得数据写入更顺序，以提高效率。目前来说，大多数存储引擎都是这样实现的，我们通常称之为**预写式日志**（Write-Ahead Logging），**修改数据需要写两次磁盘**。

事务日志可以帮助提高事务效率：
- 使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。
- 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。
- 事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回到磁盘。
- 如果数据的修改已经记录到事务日志并持久化，但数据本身没有写回到磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这一部分修改的数据。

## 1.6 事务实现
事务的实现是基于数据库的存储引擎。不同的存储引擎对事务的支持程度不一样。MySQL 中支持事务的存储引擎有 InnoDB 和 NDB。

事务的实现就是如何实现 ACID 特性。**事务的隔离性是通过锁实现**，而**事务的原子性、一致性和持久性则是通过事务日志实现** 。事务日志分为：重做日志（redo log）和回滚日志（undo log）。

### 重做日志（redo log）：
实现持久化和原子性。在 innoDB 的存储引擎中，事务日志通过 redo log 和 innoDB 存储引擎的日志缓冲(InnoDB Log Buffer)实现。
- 事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中；
- 在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是 DBA 们口中常说的“日志先行”(Write-Ahead Logging)；
- 当事务提交之后，在 Buffer Pool 中映射的数据文件才会慢慢刷新到磁盘。
- 此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据 redo log 中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。
- 在系统启动的时候，为 redo log 分配了一块连续的存储空间，以顺序追加的方式记录 Redo Log，通过顺序 IO 来改善性能。所有的事务共享 redo log 的存储空间，它们的 Redo Log 按语句的执行顺序，依次交替的记录在一起。

### 回滚日志（undo log）：
实现一致性，undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录 redo log，还会记录一定量的 undo log。undo log 记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据 undo log 进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。undo 记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的（共享表空间或者独享表空间）。

二种日志均可以视为一种恢复操作，redo log 是恢复提交事务修改的页操作，而 undo log 是回滚行记录到特定版本。二者记录的内容也不同，redo log是物理日志，记录页的物理修改操作，而undo log是逻辑日志，根据每行记录进行记录。

## 1.7 MySQL 日志的种类
- 错误日志：记录出错信息，也记录一些警告信息或者正确的信息；
- 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行；
- 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中；
- 二进制日志：记录对数据库执行更改的所有操作；
- 中继日志：中继日志也是二进制日志，用来给 slave 库恢复；
- 事务日志：重做日志和回滚日志。

## 1.8 MySQL 对分布式事务的支持
分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。

MySQL 从 5.0.3 InnoDB 存储引擎开始支持XA协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。

在 MySQL 中，使用分布式事务涉及一个或多个资源管理器和一个事务管理器。
<div align="center"> <img src="images/113.webp" width=620px"></div><br>

如上图，MySQL 的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）。
- 应用程序：定义了事务的边界，指定需要做哪些事务；
- 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器；
- 事务管理器：协调参与了全局事务中的各个事务。

### MySQL 分布式事务采用两段式提交（two-phase commit，2PC）的方式：
- 第一阶段，所有的事务节点开始准备，告诉事务管理器 ready。
- 第二阶段，事务管理器告诉每个节点是 commit 还是 rollback。如果有一个节点失败，就需要全局的节点全部 rollback，以此保障事务的原子性。

# 2 MySQL 锁机制

## 2.1 锁的分类

### 从对数据操作的类型分类：
- 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响；
- 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁。

### 从对数据操作的粒度分类：
为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），因此数据库系统需要在高并发响应和系统性能两方面进行平衡，这样就产生了“锁粒度（Lock granularity）”的概念。

- **表级锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）；

- **行级锁**：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，默认情况下采用行级锁）；
  
- **页面锁**：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如 Web 应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。

## 2.2 MyISAM 表锁
MyISAM 的表锁有两种模式：
- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

默认情况下，写锁比读锁具有更高的优先级：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

## 2.3 InnoDB 行锁
InnoDB 实现了以下两种类型的行锁：
- 共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的**意向锁**（Intention Locks），这两种意向锁都是表锁：
- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的 IS 锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的 IX 锁。

索引失效会导致行锁变表锁。如:vchar 查询不写单引号的情况。

## 2.4 加锁机制
乐观锁与悲观锁是两种并发控制的思想，可用于解决丢失更新问题。

- 乐观锁：“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式

- 悲观锁：“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，直接调用数据库的相关语句就可以了。

## 2.5 锁模式(InnoDB 三种行锁的算法)

### 记录锁(Record Locks)
**单个行记录**上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项。
```Text
-- id 列为主键列或唯一索引列
SELECT * FROM table WHERE id = 1 FOR UPDATE;
UPDATE SET age = 50 WHERE id = 1;
```
它会在 id=1 的记录上加上记录锁，以阻止其他事务插入、更新、删除；id=1 这一行在通过“主键索引”与“唯一索引”对数据行进行 UPDATE 操作时，也会对该行数据加记录锁。

### 间隙锁（Gap Locks）
当我们使用**范围条件**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。InnoDB 也会对这个“间隙”加锁，这种锁机制就是间隙锁。

对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于Next-Key Locking 算法。

使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。
```Text
SELECT * FROM table WHERE id BETWEN 1 AND 5 FOR UPDATE;
```
即所有在（1，5）区间内的记录行都会被锁住，所有id 为 2、3、4 的数据行的插入会被阻塞，但是 1 和 5 两条记录行并不会被锁住。间隙锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。

### 临键锁(Next-key Locks)
是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。

每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。(果把事务的隔离级别降级为 RC，临键锁则也会失效。)

## 2.6 死锁

### 死锁的产生：
- 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环
- 当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁
- 锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

### 检测死锁
数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB 存储引擎能检测到死锁的循环依赖并立即返回一个错误。

### 死锁恢复
死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB 目前处理死锁的方法是，**将持有最少行级排他锁的事务进行回滚**。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

### 外部锁的死锁检测
发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决。

### 死锁影响性能
死锁会影响性能而不是会产生严重错误，因为 InnoDB 会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖 innodb_lock_wait_timeout 设置进行事务回滚。

### MyISAM 避免死锁
在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

### InnoDB 避免死锁
- 为了在单个 InnoDB 表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。
- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 通过 SELECT ... LOCK IN SHARE MODE 获取行的读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。
- 改变事务隔离级别。

如果出现死锁，可以用 show engine innodb status;命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

# 3 SQL 调优




# 参考：
- [MySQL 万字精华总结](https://www.jianshu.com/p/c189439fb32e)

